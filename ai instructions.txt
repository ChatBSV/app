Product Specs

Alfred Chat App - Docs

The Alfred Chat App is a web application built with Next.js and deployed on Netlify using serverless functions. It provides a chat interface where users can interact with an AI-powered chatbot. The app utilizes the OpenAI API to generate responses based on user prompts.

File Structure

The project follows the following file structure:

├── components/
│   ├── ChatBody.js
│   ├── ChatBody.module.css
│   ├── ChatInput.js
│   ├── ChatInput.module.css
│   ├── ChatMessage.js
│   ├── ChatMessage.module.css
│   ├── Header.js
│   ├── Header.module.css
│   └── ...
├── netlify/functions/
│   ├── getChatReply.js
│   └── ...
├── pages/
│   └── index.js
├── .env
├── package.json
├── .toml
├── .postccconfig.js
└── ...

    ChatBody.js: Renders the chat messages exchanged between the user and the chatbot.

    ChatInput.js: Represents the input field where users can enter their messages.

    ChatMessage.js: Renders an individual chat message.

    Header.js: Displays the header of the application.

    ...

    getChatReply.js: Handles the processing of user messages and retrieval of AI-generated responses.

    index.js: The main page that displays the chat interface.

    .env for storing environment variables, CORE_PROMPT and OPENAI_API_KEY



--

Here's a summary of diagnostics and changes for the code:

    Sending the CORE_PROMPT as the system message with the first user message: In your getChatReply.js function, you have logic to check the conversation history length. If it's greater than 0, you include the previous message, otherwise, you include the corePrompt. The logic seems fine, but remember to store the corePrompt only in the first user's message and ensure that it's not repeated in subsequent messages.

    Optimizing to send and receive a minimum amount of characters: Since you only need content and total tokens, streamline the body of the POST request in getChatReply.js to include only necessary data. Trim unnecessary metadata from the request/response objects. Also, structure your fullPrompt array to contain only the data required (system message, user input, and previous assistant response).

    History Logic: The logic for saving the assistant message seems correct. You clear the history and save the received message after getting a response from OpenAI. Just remember to clear the history before saving a new message to maintain only the last message.

    Optimizing async functions to avoid 10s timeouts: There are a few best practices that could be implemented to prevent timeouts:

        Reduce third-party API reliance: If the OpenAI API response time is slow, it could cause your function to timeout. Always try to reduce the dependence on third-party APIs, or ensure you have adequate error handling and retry logic in place.

        Use Promise.all() to run promises concurrently, when possible: If you have several independent async operations, using Promise.all() can potentially speed up overall execution time.

        Optimize your code: Avoid blocking operations, look for ways to make your code more efficient, and reduce unnecessary operations.

        Check your timeout settings: Make sure you have set a timeout that gives your function enough time to execute. If you're making a lot of data requests, you might need to increase your timeout. However, be careful not to set it too high, as that could result in longer delays if a function gets stuck.

        Handle Errors Properly: Make sure to properly handle errors and reject a promise when an error occurs. Unhandled promise rejections can also lead to timeouts.


--




    SCRIPTS:

    // pages/index.js

// index.js

import React, { useState } from 'react';
import axios from 'axios';
import ChatBody from '../components/ChatBody';
import ChatInput from '../components/ChatInput';
import Header from '../components/Header';
import './global.css';


const IndexPage = () => {
  const [chat, setChat] = useState([]);

  const handleSubmit = async (prompt) => {
    const { OPENAI_API_KEY, CORE_PROMPT } = process.env;
  
    const fullPrompt = [
      {
        role: 'system',
        content: CORE_PROMPT,
      },
      {
        role: 'user',
        content: prompt,
      },
    ];
  
      setChat([...chat, { message: prompt, isUser: true }]);
  
    try {
      const response = await axios.post(
        'https://api.openai.com/v1/chat/completions',
        {
          model: 'gpt-3.5-turbo',
          messages: fullPrompt,
        },
        {
          headers: {
            Authorization: `Bearer ${OPENAI_API_KEY}`,
            'Content-Type': 'application/json',
          },
        }
      );
  
      const output = response.data.choices[0].message.content;
  
     
      setChat([...chat, { message: output, isUser: false }]);
    } catch (error) {
      console.error('Error:', error);
    }
  };


  return (
    <div style={{ color: '#555', backgroundColor: '#f1f1f1', flexDirection: 'column', fontFamily: 'IBM Plex Sans, sans-serif', fontSize: '16px', fontWeight: 400, lineHeight: '22px', display: 'flex', position: 'fixed', top: 0, bottom: 0, left: 0, right: 0 }}>
      <Header />
      <ChatBody chat={chat} />
      <div className="chat-footer">
      <ChatInput handleSubmit={handleSubmit} />
    </div>
    </div>
  );
};

export default IndexPage;



// components/ChatInput.js

import { useState } from 'react';
import styles from './ChatInput.module.css';

const ChatInput = ({ handleSubmit }) => {
  const [input, setInput] = useState('');

  const handleFormSubmit = (event) => {
    event.preventDefault();
    const prompt = input.trim();

    if (prompt !== '') {
      handleSubmit(prompt);
      setInput('');
    }
  };

  const handleInputChange = (event) => setInput(event.target.value);

  return (
    <form onSubmit={handleFormSubmit} className={styles.inputForm}>
      <input
        type="text"
        value={input}
        onChange={handleInputChange}
        className={styles.inputField}
        placeholder="Enter your prompt here"
      />
      <button type="submit" className={styles.submitButton}>
        Submit
      </button>
    </form>
  );
};

export default ChatInput;



// netlify/functions/getChatReply.js


const axios = require('axios');
const ChatBody = require('../../components/ChatBody');
const renderMessage = ChatBody.renderMessage;


exports.handler = async function(event, context) {
  const { OPENAI_API_KEY, CORE_PROMPT } = process.env;
  const prompt = event.body;

  const fullPrompt = [
    {
      role: 'system',
      content: CORE_PROMPT,
    },
    {
      role: 'user',
      content: prompt,
    },
  ];

  try {
    const response = await axios.post(
      'https://api.openai.com/v1/chat/completions',
      {
        model: 'gpt-3.5-turbo',
        messages: fullPrompt,
      },
      {
        headers: {
          Authorization: `Bearer ${OPENAI_API_KEY}`,
          'Content-Type': 'application/json',
        },
      }
    );

    const output = response.data.choices[0].message.content;

    renderMessage('', output, false);

    return {
      statusCode: 200,
      body: JSON.stringify({ message: output }),
    };
  } catch (error) {
    console.error('Error:', error);
    return {
      statusCode: 500,
      body: JSON.stringify({ error: 'An error occurred during processing.' }),
    };
  }
};


// components/ChatBody.js

import styles from './ChatBody.module.css';

function ChatBody({ chat }) {
  const renderMessage = (sender, message, isUser) => {
    const messageDiv = document.createElement('div');
    messageDiv.className = isUser ? 'chat-message user-message' : 'chat-message assistant-message';
    messageDiv.innerHTML = `<strong>${sender}</strong> ${message}`;
    const chatContainer = document.getElementById('chat-container');
    chatContainer.appendChild(messageDiv);
    chatContainer.scrollTop = chatContainer.scrollHeight;
  };

  return (
    <div id="chat-container" className={styles.chatBody}>
      {chat.map((message, index) => (
        <div key={index} className={`chat-message ${message.isUser ? 'user-message' : 'assistant-message'}`}>
          <strong>{message.sender}</strong> {message.message}
        </div>
      ))}
    </div>
  );
}

export default ChatBody;


// components/ChatMessage.js


import styles from './ChatMessage.module.css';

function ChatMessage({ message, user }) {
    return (
        <div className={user ? styles.userMessage : styles.assistantMessage}>
            <p>{message}</p>
        </div>
    );
}

export default ChatMessage;


// components/Header.js


import styles from './Header.module.css';

function Header() {
    return (
        <div className={styles.chatHeader}>
            <h1 className={styles.heading}>Aifred</h1>
        </div>
    );
}

export default Header;


// netlify.toml
[build]
  command = "npm run build"
  publish = "out"
  functions = "netlify/functions"

[build.environment]
  NETLIFY_NEXT_PLUGIN_SKIP = "true"


// package.json

{
  "name": "alfred",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "babel . -d dist --copy-files",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@types/node": "20.1.7",
    "@types/react": "18.2.6",
    "@types/react-dom": "18.2.4",
    "autoprefixer": "10.4.14",
    "axios": "^0.26.1",
    "dotenv": "^16.0.0",
    "eslint": "8.40.0",
    "eslint-config-next": "13.4.2",
    "isomorphic-unfetch": "^4.0.2",
    "next": "^13.4.2",
    "postcss": "8.4.23",
    "react": "18.2.0",
    "react-dom": "18.2.0",
    "tailwindcss": "3.3.2",
    "typescript": "5.0.4"
  },
  "devDependencies": {
    "@babel/core": "^7.21.8",
    "@babel/preset-env": "^7.21.5",
    "@netlify/plugin-nextjs": "^4.37.1"
  }
}
